{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code originally from [this gist](https://gist.github.com/awni/56369a90d03953e370f3964c826ed4b0).\n",
    "\n",
    "We start out by doing the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, alphabet, blank):\n",
    "        self.alphabet = alphabet\n",
    "        self.blank = blank\n",
    "    \n",
    "    def decode(self, probs, beam_size=10):\n",
    "        \"\"\"\n",
    "          Performs decoding/inference for the given output probabilities.\n",
    "          Arguments:\n",
    "          probs: The output probabilities (e.g. post-softmax) for each\n",
    "            time step. Should be an array of shape (time x output dimensions).\n",
    "            beam_size (int): Size of the beam to use during decoding.\n",
    "      \n",
    "          Returns the output label sequence and the corresponding negative\n",
    "          log-likelihood estimated by the decoder.\n",
    "        \"\"\"\n",
    "        \n",
    "        T, S = probs.shape # get the dimensions of the input\n",
    "        probs = np.log(probs) # normalise \n",
    "\n",
    "        # Elements in the beam are (prefix, (p_blank, p_no_blank))\n",
    "        # Initialise the beam with the empty sequence, a probability of\n",
    "        # 1 for ending in blank and zero for ending in non-blank (in log space).\n",
    "        beam = [(tuple(), (0.0, NEG_INF))]\n",
    "\n",
    "        for t in range(T): # Loop over time\n",
    "\n",
    "            # A default dictionary to store the next step candidates.\n",
    "            next_beam = make_new_beam()\n",
    "\n",
    "            for s in range(S): # Loop over vocabulary\n",
    "                p = probs[t, s]\n",
    "                \n",
    "                for prefix, (p_b, p_nb) in beam: # Loop over beam\n",
    "                    \n",
    "                    pass\n",
    "                \n",
    "\n",
    "\n",
    "            # Sort and trim the beam before moving on to the next time-step.\n",
    "            beam = sorted(next_beam.items(), key=lambda x : logsumexp(*x[1]), reverse=True)\n",
    "            beam = beam[:beam_size]\n",
    "\n",
    "        # Extract the best path\n",
    "        best = beam[0]\n",
    "        \n",
    "        # Return the best path\n",
    "        return (best[0], -logsumexp(*best[1]))\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
