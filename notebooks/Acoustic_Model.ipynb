{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Paths\n",
    "train_aud = '/Users/tacha/iu_research/speech_recognition/asr_workshop/data/target-segments/ru/clips/'\n",
    "train_df = '/Users/tacha/iu_research/speech_recognition/asr_workshop/data/target-segments/ru/train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alphabet \n",
    "with open('/Users/tacha/iu_research/speech_recognition/asr_workshop/iu-hse-asr-workshop/data/alphabet.txt', 'r') as fo:\n",
    "    alphabet = fo.readlines() + ['f', 'i', 'r', 'e', 'o', 'x']\n",
    "char2ind = {alphabet[i].strip():i for i in range(len(alphabet))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform functions**\n",
    "\n",
    "Transform functions are the functions that are dealing with necessary input transformations e.g. feature extraction. They are feeded directly in the data loader. It helps to speed up data manipulation in contrast to reading all the file from the hard drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maxlen(path, train_df):\n",
    "    fnames = pd.read_csv(train_df, sep='\\t')['path']\n",
    "    maxlen = 0\n",
    "    for n in tqdm(fnames):\n",
    "        waveform, sample_rate = torchaudio.load(os.path.join(path, n))\n",
    "        mfcc = torchaudio.transforms.MFCC()(waveform)\n",
    "        size = mfcc.shape[2]\n",
    "        if size > maxlen:\n",
    "            maxlen = size\n",
    "    print(\"Maxlen:\", maxlen)\n",
    "\n",
    "\n",
    "def extract_feats(path, maxlen=1083):\n",
    "    '''\n",
    "    Reads and processes one file at a time.\n",
    "    Args:\n",
    "        path: path to the file\n",
    "        maxlen: maximum length of the spectrogram for padding\n",
    "    '''\n",
    "    waveform, sample_rate = torchaudio.load(path)\n",
    "    #Calculate MFCC\n",
    "    mfcc = torchaudio.transforms.MFCC()(waveform)\n",
    "    #Calculate delta and double-delta\n",
    "    deltas = torchaudio.transforms.ComputeDeltas()(mfcc)\n",
    "    ddeltas = torchaudio.transforms.ComputeDeltas()(deltas)\n",
    "    res = torch.cat((mfcc, deltas, ddeltas), dim=1).squeeze(0)\n",
    "    #Normalize rows\n",
    "    s = torch.sum(res, dim=1, keepdim=True)\n",
    "    norm = torch.div(res, s)\n",
    "    mask = torch.ones(1, norm.shape[1])\n",
    "    padded_norm = nn.functional.pad(norm, pad=(0, maxlen-norm.shape[1], 0, 0), \n",
    "                                          mode=\"constant\",value=0)\n",
    "    padded_mask = nn.functional.pad(mask, pad=(0, maxlen-mask.shape[1], 0, 0), \n",
    "                                          mode=\"constant\",value=0)\n",
    "    return padded_norm, padded_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(data.Dataset):\n",
    "    def __init__(self, csv_path, aud_path, transform):\n",
    "        self.df = pd.read_csv(csv_path, sep='\\t')\n",
    "        self.aud_path = aud_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        fname = os.path.join(self.aud_path, self.df['path'][idx])\n",
    "        transcript = self.df['sentence'][idx].lower()\n",
    "\n",
    "        feat, mask = self.transform(fname)\n",
    "\n",
    "        sample = {'aud':feat, 'trans': transcript, 'mask':mask}\n",
    "        return sample\n",
    "    \n",
    "def weights(m):\n",
    "    '''\n",
    "    Intialize weights randomly\n",
    "    '''\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposed Architechture**\n",
    "\n",
    "Attention-based Sequence-to-Sequence model:\n",
    "\n",
    "![](/img/arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(120, 512)\n",
    "        self.blstm = nn.LSTM(input_size=512, \n",
    "                             hidden_size=256, \n",
    "                             num_layers=3, \n",
    "                             bidirectional=True)\n",
    "        self.h0 = torch.zeros(3*2, batch_size, 256)\n",
    "        self.c0 = torch.zeros(3*2, batch_size, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Pass through the first linear layer\n",
    "        outputs=[]\n",
    "        for i in range(x.shape[2]):\n",
    "            feature = x[:,:,i]\n",
    "            out = self.input_layer(feature)\n",
    "            out = torch.nn.LeakyReLU()(out)\n",
    "            outputs.append(out)\n",
    "        outputs = torch.stack(outputs)\n",
    "        #Pass through LSTM layers\n",
    "        output, (hn, cn) = self.blstm(outputs, (self.h0, self.c0))\n",
    "        return output, (hn, cn)\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, h_e, h_d):\n",
    "        score = torch.matmul(h_e.T, h_d)\n",
    "        temp1 = torch.exp(score)\n",
    "        temp2 = torch.sum(score, dim=0)\n",
    "        a_t = temp1/temp2\n",
    "        c_t = torch.zeros(h_e.shape)\n",
    "        for a in a_t:\n",
    "            c_t+=a*h_e  \n",
    "        return c_t\n",
    "        \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.char2ind = char2ind\n",
    "        self.embed_layer = nn.Linear(33, 128)\n",
    "        self.lstm_cell = nn.LSTMCell(128, 512)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.output = nn.Linear(512, 33)\n",
    "        self.dec_h = torch.zeros(batch_size, 512)\n",
    "        self.c = torch.zeros(batch_size, 512)\n",
    "        self.y = torch.zeros(batch_size,  33)\n",
    "        self.attention = Attention()\n",
    "    \n",
    "    def forward(self, enc_h):\n",
    "        preds = []\n",
    "        for hidden in enc_h:\n",
    "            c_t = self.attention(hidden, self.dec_h)\n",
    "            y = self.embed_layer(self.y)\n",
    "            self.dec_h, self.c = self.lstm_cell(y, (self.dec_h, self.c))\n",
    "            self.y = self.output(self.dec_h)\n",
    "            y_hat = torch.argmax(self.softmax(self.y), dim=1)\n",
    "            preds.append(y_hat)\n",
    "        return torch.stack(preds).T\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(batch_size)\n",
    "        self.decoder = Decoder(batch_size)\n",
    "    def forward(self, batch):\n",
    "        enc_out, (he, ce) = encoder(batch)\n",
    "        preds = decoder(enc_out)\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "def encode_trans(trans, char2ind, maxlen_t=7):\n",
    "    '''\n",
    "    Encodes true transcription\n",
    "    trans: \n",
    "    '''\n",
    "    sent_ind = []\n",
    "    for sent in trans:\n",
    "        res = np.array([char2ind[char] for char in sent])\n",
    "        res = np.pad(res, (0, maxlen_t-len(res)), 'constant', constant_values=(-1))\n",
    "        sent_ind.append(res)\n",
    "    return torch.tensor(sent_ind)\n",
    "    \n",
    "def collapse_fn(preds, masks):\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    masks = masks.detach().cpu().numpy()\n",
    "    collapsed = []\n",
    "    maxlen_t = 0\n",
    "    for pred, mask in zip(preds, masks):\n",
    "        temp = [pred[0]]\n",
    "        for i, char in enumerate(pred[1:]):\n",
    "            if mask[i]:\n",
    "                if pred[i-1]==char:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp.append(char)\n",
    "        collapsed.append(temp)\n",
    "        maxlen_t = max(maxlen_t, len(temp))\n",
    "    \n",
    "    res = []\n",
    "    for sent in collapsed:\n",
    "        sent = np.pad(sent, (0, maxlen_t - len(sent)), 'constant', constant_values=(-1))\n",
    "        res.append(sent)\n",
    "        \n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Seq2Seq(32)\n",
    "model.apply(weights)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CTCLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "cv_dataset = TrainData(train_df, train_aud, extract_feats)\n",
    "loader = data.DataLoader(cv_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 7])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-585-5b5d1b49de20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollapse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/prog/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-582-1783b4e0017d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/prog/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-537-afb58bd87582>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_h)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menc_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/prog/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-537-afb58bd87582>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h_e, h_d)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mc_t\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    x = batch['aud'].to(device)\n",
    "    t = encode_trans(batch['trans'], char2ind).to(device)\n",
    "    print(t.shape)\n",
    "    mask = batch['mask'].squeeze(1)\n",
    "    preds = model(x)\n",
    "    preds = collapse_fn(preds, mask)\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
